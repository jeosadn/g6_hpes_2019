{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neuronal Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from os import environ\n",
    "logging.disable(logging.WARNING)  # Suppress deprecation warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero se importan todas las funciones a utilizar de la librería Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se definen algunos parámetros que se utilizan en el preprocesado como el nuevo tamaño de las imágenes y la normalización de los píxeles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model params(\n",
    "img_rows   = 80  # Training data size is 480\n",
    "img_cols   = 80  # Training data size is 480\n",
    "rescale    = 1./255\n",
    "batch_size = 10\n",
    "num_epoch  = 6\n",
    "classes    = ['d4', 'd6', 'd8', 'd10', 'd12', 'd20']\n",
    "directory  = './dice/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los parámetros que se definieron se realiza el preprocesado utilizando la función ImageDataGenerator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing\n",
      "Found 14284 images belonging to 6 classes.\n",
      "Found 2102 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "print('Data preprocessing')\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "    directory   = directory + './train/',\n",
    "    target_size = (img_rows, img_cols),\n",
    "    classes     = classes,\n",
    "    color_mode  = 'grayscale',\n",
    "    batch_size  = batch_size,\n",
    ")\n",
    "        \n",
    "valid_generator = ImageDataGenerator(rescale=1./255,).flow_from_directory(\n",
    "    directory   = directory + './valid/',\n",
    "    target_size = (img_rows, img_cols),\n",
    "    classes     = classes,\n",
    "    color_mode  = 'grayscale',\n",
    "    batch_size  = batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se procede a construir el modelo de aprendizaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 78, 78, 8)         80        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 76, 76, 16)        1168      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 74, 74, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 82944)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                5308480   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 5,333,254\n",
      "Trainable params: 5,333,254\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Model design\n",
    "model = Sequential()\n",
    "\n",
    "# Adding convolution and pooling layers\n",
    "model.add(Conv2D(8,kernel_size=(3,3),activation='relu',input_shape=input_shape))\n",
    "model.add(Conv2D(16,kernel_size=(3,3),activation='relu'))\n",
    "model.add(Conv2D(32,kernel_size=(3,3),activation='relu'))\n",
    "model.add(Conv2D(64,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Randomly turn on and off some neurons to improve convergence\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Adding flatten layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Adding fully connected layer\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Adding softmax layer for final categorization\n",
    "model.add(Dense(len(classes),activation='softmax'))\n",
    "\n",
    "# Compile model with Adadelta optimizer\n",
    "model.compile(loss=categorical_crossentropy,optimizer=Adadelta(),metrics=['accuracy'])\n",
    "\n",
    "# Model summary:\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solo falta entrenar el modelo, se van a utilizar 6 iteraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "1429/1429 [==============================] - 286s 200ms/step - loss: 1.2126 - acc: 0.5131 - val_loss: 0.6177 - val_acc: 0.8092\n",
      "Epoch 2/6\n",
      "1429/1429 [==============================] - 295s 206ms/step - loss: 0.5858 - acc: 0.7861 - val_loss: 0.3815 - val_acc: 0.9144\n",
      "Epoch 3/6\n",
      "1429/1429 [==============================] - 280s 196ms/step - loss: 0.3729 - acc: 0.8636 - val_loss: 0.2858 - val_acc: 0.9477\n",
      "Epoch 4/6\n",
      "1429/1429 [==============================] - 332s 232ms/step - loss: 0.2789 - acc: 0.8992 - val_loss: 0.3353 - val_acc: 0.9320\n",
      "Epoch 5/6\n",
      "1429/1429 [==============================] - 366s 256ms/step - loss: 0.2468 - acc: 0.9100 - val_loss: 0.2975 - val_acc: 0.9405\n",
      "Epoch 6/6\n",
      "1429/1429 [==============================] - 280s 196ms/step - loss: 0.2266 - acc: 0.9220 - val_loss: 0.2609 - val_acc: 0.9567\n",
      "Training time: 1840s\n"
     ]
    }
   ],
   "source": [
    "# Model training\n",
    "start = time.time()\n",
    "\n",
    "model_hist = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=num_epoch,\n",
    "    verbose=1,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=len(valid_generator)\n",
    ")\n",
    "        \n",
    "end = time.time()\n",
    "print(\"Training time: {:.0f}s\".format(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver que en la última iteración se alcanzó una precisión de un 95,67% en el set de validación.\n",
    "\n",
    "El siguiente paso el evaluar la red utilizando el set de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40 images belonging to 6 classes.\n",
      "loss: 0.00357031896806\n",
      "acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Model results on the ./test dataset:\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "    directory   ='./test/',\n",
    "    target_size =(img_rows, img_cols),\n",
    "    classes     =classes,\n",
    "    color_mode  ='grayscale',\n",
    "    batch_size  =batch_size\n",
    ")\n",
    "    \n",
    "model_results = model.evaluate_generator(test_generator, steps=len(test_generator))\n",
    "model_results\n",
    "\n",
    "for idx, label in enumerate(model.metrics_names):\n",
    "    print('{}: {}'.format(label, model_results[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último se puede ver como en el set de prueba se acertaron todas las etiquetas de las imágenes por lo que se concluye que se logró un modelo de aprendizaje que generaliza muy bien."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
